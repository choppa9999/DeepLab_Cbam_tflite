import os
import argparse
import numpy as np
import tensorflow as tf
from PIL import Image
from tqdm import tqdm

def create_pascal_label_colormap():
    """PASCAL VOCì™€ ìœ ì‚¬í•œ ì»¬ëŸ¬ë§µì„ ìƒì„±í•©ë‹ˆë‹¤."""
    colormap = np.zeros((256, 3), dtype=int)
    ind = np.arange(256, dtype=int)
    for shift in reversed(range(8)):
        for channel in range(3):
            colormap[:, channel] |= ((ind >> channel) & 1) << shift
        ind >>= 3
    return colormap

def label_to_color_image(label):
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¼ë²¨(í´ë˜ìŠ¤ ID)ì„ ì»¬ëŸ¬ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if label.ndim != 2:
        raise ValueError(f'labelì€ 2D ë°°ì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬ shape: {label.shape}')
    colormap = create_pascal_label_colormap()
    return colormap[label].astype(np.uint8)


def run_inference(args):
    """
    TFLite ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    Args:
        args (argparse.Namespace): ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹œ ì „ë‹¬ëœ ì¸ì.
    """
    model_path = args.model_path
    input_path = args.input_path
    output_dir = args.output_dir
    save_mode = args.save_mode
    
    print(f"TFLite ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}")
    try:
        interpreter = tf.lite.Interpreter(model_path=model_path)
        interpreter.allocate_tensors()
    except Exception as e:
        print(f"ì˜¤ë¥˜: TFLite ëª¨ë¸ íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: {e}")
        return

    input_details = interpreter.get_input_details()[0]
    output_details = interpreter.get_output_details()[0]
    _, height, width, _ = input_details['shape']
    print(f"ëª¨ë¸ ì…ë ¥ í¬ê¸°: ({height}, {width})")

    image_paths = []
    supported_extensions = ('.png', '.jpg', '.jpeg', '.bmp')
    if os.path.isdir(input_path):
        for filename in os.listdir(input_path):
            if filename.lower().endswith(supported_extensions):
                image_paths.append(os.path.join(input_path, filename))
    elif os.path.isfile(input_path) and input_path.lower().endswith(supported_extensions):
        image_paths.append(input_path)

    if not image_paths:
        print(f"ì˜¤ë¥˜: '{input_path}' ê²½ë¡œì—ì„œ ì²˜ë¦¬í•  ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    os.makedirs(output_dir, exist_ok=True)
    print(f"ì´ {len(image_paths)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤. ê²°ê³¼ëŠ” '{output_dir}'ì— ì €ì¥ë©ë‹ˆë‹¤.")

    for image_path in tqdm(image_paths, desc="TFLite ì¶”ë¡  ì§„í–‰ë¥ "):
        try:
            original_image = Image.open(image_path).convert('RGB')
            original_size = original_image.size
            resized_image = original_image.resize((width, height))

            input_type = input_details['dtype']
            
            if 'printed_info' not in locals():
                print(f"\nğŸ’¡ ì •ë³´: ëª¨ë¸ì´ ì˜ˆìƒí•˜ëŠ” ì…ë ¥ íƒ€ì…ì€ '{np.dtype(input_type).name}' ì…ë‹ˆë‹¤.")
                printed_info = True

            if input_type == np.uint8:
                input_data = np.array(resized_image, dtype=np.uint8)
                input_data = np.expand_dims(input_data, axis=0)
            else:
                image_np_float = np.array(resized_image, dtype=np.float32)
                image_batch = np.expand_dims(image_np_float, axis=0)
                input_data = tf.keras.applications.mobilenet_v2.preprocess_input(image_batch)
            
            interpreter.set_tensor(input_details['index'], input_data)
            interpreter.invoke()

            output_data = interpreter.get_tensor(output_details['index'])
            seg_map = np.squeeze(output_data).astype(np.uint8)

            seg_map_pil = Image.fromarray(seg_map)
            resized_seg_map = seg_map_pil.resize(original_size, Image.NEAREST)
            
            # --- [ìˆ˜ì •] ì €ì¥ ëª¨ë“œì— ë”°ë¼ ë‹¤ë¥¸ ì´ë¯¸ì§€ ìƒì„± ë° ì €ì¥ ---
            color_mask_image = label_to_color_image(np.array(resized_seg_map))
            original_image_np = np.array(original_image)
            overlayed_image = (original_image_np * 0.6 + color_mask_image * 0.4).astype(np.uint8)
            
            base_filename = os.path.basename(image_path)
            filename_no_ext, _ = os.path.splitext(base_filename)

            if save_mode in ['comparison', 'all']:
                comparison_image = np.hstack((original_image_np, color_mask_image, overlayed_image))
                comparison_path = os.path.join(output_dir, f"{filename_no_ext}_comparison.png")
                Image.fromarray(comparison_image).save(comparison_path)

            if save_mode in ['overlay', 'all']:
                output_path = os.path.join(output_dir, f"{filename_no_ext}_overlay.png")
                Image.fromarray(overlayed_image).save(output_path)
            # -----------------------------------------------------------

        except Exception as e:
            print(f"\nì˜¤ë¥˜: '{image_path}' ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            import traceback
            traceback.print_exc()

    print("\n--- ëª¨ë“  ì¶”ë¡  ì™„ë£Œ ---")


def main():
    parser = argparse.ArgumentParser(description="TFLite DeepLabV3+ CBAM ëª¨ë¸ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument('--model_path', type=str, required=True,
                        help="ì¶”ë¡ ì— ì‚¬ìš©í•  .tflite ëª¨ë¸ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument('--input_path', type=str, required=True,
                        help="ì¶”ë¡ í•  ì…ë ¥ ì´ë¯¸ì§€ ë˜ëŠ” í´ë” ê²½ë¡œ")
    parser.add_argument('--output_dir', type=str, required=True,
                        help="ì¶”ë¡  ê²°ê³¼ë¥¼ ì €ì¥í•  í´ë” ê²½ë¡œ")
    # --- [ì¶”ê°€] ì €ì¥ ëª¨ë“œ ì¸ì ---
    parser.add_argument(
        '--save_mode',
        type=str,
        default='overlay',
        choices=['overlay', 'comparison', 'all'],
        help="ì¶”ë¡  ê²°ê³¼ ì €ì¥ ë°©ì‹: 'overlay' (ë®ì–´ì“°ê¸°), 'comparison' (ë¹„êµ), 'all' (ëª¨ë‘)"
    )
    # --------------------------
    args = parser.parse_args()

    run_inference(args)


if __name__ == '__main__':
    main()

